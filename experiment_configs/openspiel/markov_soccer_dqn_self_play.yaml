markov_soccer_dqn_self_play:
    run: SELF_PLAY
    stop:
        self_play_rounds: 20
    checkpoint_at_end: True
    num_samples: 5
    config:
        alg: DQN
        # === Self Play ===
        symmetric: False
        self_play_round_stop: 
            training_iteration: 50
        self_play_pretrain_stop:
            training_iteration: 0
        # === Evaluation ===
        population:
          - path: populations/markov_soccer_ppo
            alg: SIMULTANEOUS_PLAY
            mapping: [[1, learned_policy_1]]
        random_eval: True
        multiagent_eval_interval: 20
        # === Environment ===
        horizon: 200
        env: openspiel
        env_config:
            game: markov_soccer
        # === DQN ===
        dueling: True
        double_q: True
        n_step: 1
        timesteps_per_iteration: 1600
        target_network_update_freq: 500
        buffer_size: 50000
        prioritized_replay: True
        gamma: 0.95
        lr: 0.001
        train_batch_size: 32
        rollout_fragment_length: 4
        batch_mode: truncate_episodes
        # === Exploration ===
        exploration_config: 
          type: EpsilonGreedy
          initial_epsilon: 1.0
          final_epsilon: 0.02
          epsilon_timesteps: 400000