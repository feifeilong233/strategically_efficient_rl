multi_matrix_contextual_self:
  run: SELF_PLAY
  stop:
    self_play_rounds: 20
  checkpoint_at_end: True
  checkpoint_freq: 100
  num_samples: 2
  config:
    alg: DEEP_NASH_V2
    evaluation_interval: 1
    # === Evaluation ===
#    population:
#      - path: populations/multi_matrix_2contextual_eval
#        alg: DEEP_NASH_V2
#        mapping: [ [ 0, policy_0 ] ]
#    random_eval: True
    multiagent_eval_interval: 20
    # === Self Play ===
    symmetric: False
    self_play_round_stop:
      training_iteration: 50
    self_play_pretrain_stop:
      training_iteration: 0
    # === Environment ===
    env: multi_matrix
    env_config:
      num_contexts: 3
    # === Curiosity ===
    model:
      custom_options:
        start_weight: 1.0
        end_weight: 0.0
        exploration_steps: 70000
        burn_in: 8000
        delay: 4000
        decay: 0.02
        curiosity_module: RND
        curiosity_config:
          scale: 0.5
          fcnet_activation: elu
          fcnet_hiddens: [ 256, 256 ]
          fcnet_outputs: 32
          agent_action: True
          joint_action: True
    # === Intrinsic PPO ===
    intrinsic_gamma: 0.95
    intrinsic_lambda: 0.95
    num_agents: 2
    # === PPO ===
    lambda: 0.95
    gamma: 0.95
    entropy_coeff: 0.001
    clip_param: 0.1
    lr: 0.000001
    num_sgd_iter: 8
    sgd_minibatch_size: 32
    train_batch_size: 1600
    rollout_fragment_length: 200
    batch_mode: truncate_episodes
#    average_buffer_size: 50000
#    average_minibatch_size: 32
