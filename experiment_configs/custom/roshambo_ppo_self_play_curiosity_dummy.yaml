self_play_rnd_tune_dummy:
    run: PPO_CURIOSITY
    stop:
        timesteps_total: 50000
    checkpoint_at_end: True
    num_samples: 2
    config:
        evaluation_interval: 1
        # === Environment ===
        env: roshambo
        env_config:
            transitive_actions: 3
            cyclic_actions: 0
            num_contexts: 8
            eval_steps: 100
        # === Curiosity ===
        model:
            custom_options: 
                weight: 
                    grid_search:
                        - 0.1
                        - 0.5
                        - 2.0
                decay: 
                    grid_search: 
                        - 0.02
                        - 0.2
                burn_in: 1600
                delay: 800
                curiosity_module: RND
                curiosity_config:
                    fcnet_activation: relu
                    fcnet_hiddens: [32, 32]
                    fcnet_outputs: 32
                    agent_action: True
                    joint_action: False
        # === Intrinsic PPO ===
        intrinsic_gamma: 0.95
        intrinsic_lambda: 0.95
        num_agents: 2
        # === Self Play ===
        self_play:
            burn_in: True
            round:
                timesteps_total: 2000
        horizon: 200
        # === PPO ===
        lambda: 0.95
        gamma: 0.99
        entropy_coeff: 0.001
        clip_param: 0.1
        lr: 0.0001
        num_sgd_iter: 8
        sgd_minibatch_size: 32
        train_batch_size: 160
        rollout_fragment_length: 40
        batch_mode: complete_episodes